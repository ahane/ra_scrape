{
 "metadata": {
  "name": "",
  "signature": "sha256:686324f478c4c5d60f313425a1669d2141da200b19b7533ae4de370228919f50"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%writefile ra/items.py\n",
      "import scrapy\n",
      "\n",
      "class Event(scrapy.Item):\n",
      "    #item_type = scrapy.Field(default='event')\n",
      "    item_type = scrapy.Field()\n",
      "    ra_event_id = scrapy.Field()\n",
      "    ra_url = scrapy.Field()\n",
      "    name = scrapy.Field()    \n",
      "    start_datetime = scrapy.Field()\n",
      "    end_datetime = scrapy.Field()\n",
      "    #ra_club_id = scrapy.Field()\n",
      "    \n",
      "    #these fields are for a document-like serving\n",
      "    club = scrapy.Field()\n",
      "    artists = scrapy.Field()\n",
      "    \n",
      "class Club(scrapy.Item):\n",
      "    item_type = scrapy.Field(default='club')\n",
      "    ra_club_id = scrapy.Field()\n",
      "    ra_url = scrapy.Field()\n",
      "    name = scrapy.Field()\n",
      "    adress = scrapy.Field()\n",
      "    lat = scrapy.Field()\n",
      "    lon = scrapy.Field()\n",
      "    ra_locale_id = scrapy.Field()\n",
      "\n",
      "class Performance(scrapy.Item):\n",
      "    item_type = scrapy.Field(default='performance')\n",
      "    ra_event_id = scrapy.Field()\n",
      "    sc_artist_id = scrapy.Field()\n",
      "    artist = scrapy.Field()\n",
      "    \n",
      "class Artist(scrapy.Item):\n",
      "    item_type = scrapy.Field(default='artist')\n",
      "    ra_artist_id = scrapy.Field()\n",
      "    ra_url = scrapy.Field()\n",
      "    name = scrapy.Field()\n",
      "    sc_user = scrapy.Field()\n",
      "    sc_url = scrapy.Field()\n",
      "    #sc_track_permalink = scrapy.Field()\n",
      "    #sc_track_id = scrapy.Field()\n",
      "    #sc_value = scrapy.Field() #arbitray number for rankin artists\n",
      "    \n",
      "class Track(scrapy.Item):\n",
      "    artist_id = scrapy.Field()\n",
      "    sc_track_id = scrapy.Field()\n",
      "    sc_user_name = scrapy.Field()\n",
      "    sc_num_plays = scrapy.Field()\n",
      "    sc_description = scrapy.Field()\n",
      "    sc_genre = scrapy.Field()\n",
      "    sc_embeddable_by = scrapy.Field()\n",
      "    sc_lable_name = scrapy.Field()\n",
      "    sc_last_modiefied = scrapy.Field()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting ra/items.py\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 250
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%writefile ra/spiders/event_spider.py\n",
      "import scrapy\n",
      "from scrapy.contrib.spiders import CrawlSpider, Rule\n",
      "from scrapy.contrib.linkextractors import LinkExtractor\n",
      "scrapy.contrib.linkextractors.lxmlhtml.LxmlLinkExtractor\n",
      "from ra.items import Event, Club, Performance, Artist\n",
      "import urllib\n",
      "import datetime\n",
      "import re\n",
      "import json\n",
      "import geocoder\n",
      "from collections import defaultdict\n",
      "BASE_URL = 'http://www.residentadvisor.net'\n",
      "LISTINGS_EXT = '/events.aspx?'\n",
      "BERLIN_AI = 34\n",
      "TODAY = datetime.date.today()\n",
      "#TODAY = datetime.date(2014, 9, 29)\n",
      "\n",
      "listing_params = {'ai': BERLIN_AI,\n",
      "                  'v': 'day',\n",
      "                  'mn': TODAY.month,\n",
      "                  'yr': TODAY.year,\n",
      "                  'dy': TODAY.day}\n",
      "today_events_url = BASE_URL + LISTINGS_EXT + urllib.urlencode(listing_params)\n",
      "\n",
      "\n",
      "# Helper Functions\n",
      "def datetimes_from_date_div(date_div):\n",
      "    ''' Extracts start and end datetimes from\n",
      "        the resident advisor date div\n",
      "    '''\n",
      "    \n",
      "    links = date_div.xpath('a/@href').extract()\n",
      "    num_date_links = len(links)\n",
      "    start_date = date_from_events_url(links[0])\n",
      "    end_date = None\n",
      "    if num_date_links > 1:\n",
      "        end_date = date_from_events_url(links[-1])\n",
      "    \n",
      "    start_time, end_time = times_from_str(date_div.extract())\n",
      "    \n",
      "    start_datetime, end_datetime = join_times_dates(start_date, end_date, start_time, end_time)\n",
      "    \n",
      "    return start_datetime, end_datetime\n",
      "\n",
      "def date_from_events_url(url):\n",
      "    from urlparse import parse_qs, urlparse\n",
      "    from datetime import date\n",
      "    date_dict = parse_qs(urlparse(url).query, keep_blank_values=True)\n",
      "    try:\n",
      "        y = int(date_dict['yr'][0])\n",
      "        m = int(date_dict['mn'][0])\n",
      "        d = int(date_dict['dy'][0])\n",
      "    except:\n",
      "        raise\n",
      "    return date(y, m , d)\n",
      "\n",
      "def times_from_str(string):\n",
      "    '''\n",
      "        Looks for '12:00 - 13:00' in a string and returns\n",
      "        both times as python time objects.\n",
      "    '''\n",
      "    def time_from_str(time_str):\n",
      "        return datetime.datetime.strptime(time_str, '%H:%M').time()\n",
      "    \n",
      "    def search_start_end(string):\n",
      "        match = re.search('(\\d\\d\\:\\d\\d)\\s\\-\\s(\\d\\d\\:\\d\\d)', string)\n",
      "        if match:\n",
      "            start_str = match.group(1)\n",
      "            start_time = time_from_str(start_str)\n",
      "            \n",
      "            end_str = match.group(2)\n",
      "            end_time = time_from_str(end_str)\n",
      "        else:\n",
      "            raise KeyError('Coulnt find start and end times')\n",
      "        \n",
      "        return start_time, end_time\n",
      "            \n",
      "    def search_start(string):\n",
      "        match = re.search('(\\d\\d\\:\\d\\d)', string)\n",
      "        if match:\n",
      "            start_str = match.group(1)\n",
      "            start_time = time_from_str(start_str)\n",
      "       \n",
      "        else:\n",
      "            raise KeyError('Couldnt find start time')\n",
      "        \n",
      "        return start_time\n",
      "    \n",
      "    start_time, end_time = None, None\n",
      "    \n",
      "    try:\n",
      "        start_time, end_time = search_start_end(string)\n",
      "    except KeyError:\n",
      "        try:\n",
      "            start_time = search_start(string)\n",
      "        except KeyError:\n",
      "            pass\n",
      "    return start_time, end_time\n",
      "\n",
      "def join_times_dates(start_date, end_date, start_time, end_time):\n",
      "    ''' Takes one or more dates and two times and turns them\n",
      "        into a start datetime and an end datetime.\n",
      "    '''    \n",
      "    \n",
      "    DEFAULT_START_TIME = '23:59'\n",
      "    DEFAULT_DURATION = 6\n",
      "    \n",
      "    from datetime import datetime, timedelta\n",
      "    \n",
      "    \n",
      "    def same_day(st, et):\n",
      "        if not st or not et:\n",
      "            return True\n",
      "        else:\n",
      "            return st <= et\n",
      "    \n",
      "    def datetime_from_date_time(date, time):\n",
      "        dt = datetime(date.year, date.month, date.day, time.hour, time.minute)\n",
      "        return dt\n",
      "    \n",
      "    if not start_time:\n",
      "        start_time  = datetime.datetime.strptime(DEFAULT_START_TIME, '%H:%M').time()\n",
      "    \n",
      "    start_datetime = datetime_from_date_time(start_date, start_time)\n",
      "    \n",
      "    \n",
      "    # If we didn't receive a end_date and the end time is\n",
      "    # after the start time, the event ends on the same day.\n",
      "    if not end_date and same_day(start_time, end_time):\n",
      "        end_date = start_date\n",
      "    \n",
      "    # If no end_date and end time is before start time\n",
      "    # the event ends one day after the start date\n",
      "    elif not end_date and not same_day(start_time, end_time):\n",
      "        end_date = start_date + timedelta(1) #add one day\n",
      "    \n",
      "    # Otherwise we use the end_date we got passed\n",
      "    else:\n",
      "        pass\n",
      "    \n",
      "    if not end_time:\n",
      "        duration = timedelta(hours=DEFAULT_DURATION)\n",
      "        end_datetime = start_datetime + duration\n",
      "        end_time = end_datetime.time()\n",
      "    \n",
      "    end_datetime = datetime_from_date_time(end_date, end_time)\n",
      "    \n",
      "    return start_datetime, end_datetime\n",
      "\n",
      "# Actual Spider:\n",
      "class RAEventSpider(CrawlSpider):\n",
      "    name = 'event_spider'\n",
      "    allowed_domains = [BASE_URL, 'www.residentadvisor.net', 'api.soundcloud.com']\n",
      "    start_urls = [today_events_url]\n",
      "    locale = listing_params['ai']\n",
      "    rules = [\n",
      "        Rule(LinkExtractor(allow=(r'\\/event\\.aspx\\?',), canonicalize=False),\n",
      "             callback='parse_event'),\n",
      "    ]\n",
      "\n",
      "    extract_digits = re.compile(r'(\\d+)')\n",
      "     \n",
      "    def parse_event(self, response):\n",
      "        '''\n",
      "            @url http://www.residentadvisor.net/events.aspx?ai=34&v=day&mn=10&yr=2014&dy=20\n",
      "            @returns requests 5\n",
      "            @returns items 1\n",
      "        '''\n",
      "        \n",
      "        event = Event()\n",
      "        event['ra_url'] = response.url    \n",
      "        event['ra_event_id'] = self.extract_digits.search(event['ra_url']).group(1)\n",
      "        event['item_type'] = 'event'\n",
      "        \n",
      "        event_title = response.xpath(\"//div[@id = 'sectionHead']/h1/text()\").extract()[0]\n",
      "        event['name'] = re.match('(.+)\\sat.+$', event_title).group(1) #remove 'at LOCATION'\n",
      "        \n",
      "        date_div = response.xpath(\"//div[text()='Date /']/..\")[0]\n",
      "        \n",
      "        start, end = datetimes_from_date_div(date_div)\n",
      "        event['start_datetime'], event['end_datetime'] = start.isoformat(), end.isoformat()\n",
      "        event['artists'] = []\n",
      "       \n",
      "        club_link = response.xpath(\"//a[contains(@title, 'Club profile')]\")\n",
      "        if club_link:\n",
      "            club = Club()\n",
      "            club['ra_locale_id'] = self.locale\n",
      "            club['ra_url'] = BASE_URL + '/' + club_link.xpath(\"@href\").extract()[0]\n",
      "            club['name'] = club_link.xpath(\"text()\").extract()[0]\n",
      "            id_match = self.extract_digits.search(club['ra_url'])\n",
      "            #self.log(type(id_match))\n",
      "            club['ra_club_id'] = id_match.group(1)\n",
      "            club['adress'] = club_link.xpath(\"../text()\").extract()[0]\n",
      "            \n",
      "            ## Todo: move geocoding into sperate scraper\n",
      "            geocode = geocoder.google(club['adress'])\n",
      "            if geocode.status_description == 'OK':\n",
      "\n",
      "                club['lat'] = geocode.latlng[0]\n",
      "                club['lon'] = geocode.latlng[1]\n",
      "            #event['ra_club_id'] = club['ra_club_id']\n",
      "            event['club'] = club\n",
      "        \n",
      "        lineup_selector = response.css(\".lineup\").xpath(\"a\")\n",
      "        if lineup_selector:\n",
      "            num_artists = len(lineup_selector)\n",
      "            for link_sel in lineup_selector:\n",
      "                artist = Artist()\n",
      "                url_ext = link_sel.xpath(\"@href\").extract()[0]\n",
      "                if url_ext[:4] == \"/dj/\":\n",
      "                    artist['ra_url'] = BASE_URL + url_ext\n",
      "                    artist['name'] = link_sel.xpath(\"text()\").extract()[0]\n",
      "                    artist['ra_artist_id'] = url_ext.split(\"/\")[2]\n",
      "                    \n",
      "                    #step into RA artist page\n",
      "                    request = scrapy.Request(artist['ra_url'], callback=self.parse_artist_page)\n",
      "                    request.meta['event'] = event\n",
      "                    request.meta['artist'] = artist\n",
      "                    request.meta['num_artists'] = num_artists\n",
      "                    yield request\n",
      "        else:\n",
      "            yield event\n",
      "    \n",
      "    def parse_artist_page(self, response):\n",
      "        \n",
      "        artist = response.meta['artist']\n",
      "        event = response.meta['event']\n",
      "        \n",
      "        sc_link_sel = response.xpath(\"//a[contains(@href, 'http://www.soundcloud.com')][contains(text(), 'SoundCloud')]/@href\")\n",
      "        if sc_link_sel:\n",
      "            artist['sc_url'] = sc_link_sel.extract()[0]\n",
      "            artist['sc_user'] = artist['sc_url'].split('/')[-1]\n",
      "        \n",
      "        event['artists'] = event['artists'] + [artist]\n",
      "        if response.meta['num_artists'] == len(event['artists']):\n",
      "            yield event    \n",
      "    \n",
      "    \n",
      "\n",
      "    \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting ra/spiders/event_spider.py\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%writefile ra/spiders/sc_tracks.py\n",
      "import urllib\n",
      "import json\n",
      "from ra.items import Track\n",
      "import scrapy\n",
      "from scrapy.contrib.spiders import CrawlSpider, Rule\n",
      "# artist_id = scrapy.Field()\n",
      "# sc_track_id = scrapy.Field()\n",
      "# sc_user_name = scrapy.Field()\n",
      "# sc_num_plays = scrapy.Field()\n",
      "# sc_description = scrapy.Field()\n",
      "# sc_genre = scrapy.Field()\n",
      "# sc_embeddable_by = scrapy.Field()\n",
      "# sc_lable_name = scrapy.Field()\n",
      "# sc_last_modiefied = scrapy.Field()\n",
      "class SoundCloudSpider(CrawlSpider):\n",
      "    name = 'sc_track_spider'\n",
      "    allowed_domains = ['api.soundcloud.com']\n",
      "\n",
      "    def __init__(self):\n",
      "        with open('sc_cl_id.txt', 'r') as f:\n",
      "            SC_CLIENT_ID = f.read().rstrip()\n",
      "            sc_client_id = urllib.urlencode({\"client_id\": SC_CLIENT_ID})\n",
      "        TRACKS_URL = \"http://api.soundcloud.com/users/%s/tracks.json?\"+sc_client_id\n",
      "        \n",
      "        self.users_dict = get_sc_users_without_tracks()\n",
      "        self.user_names = users_dict.keys()\n",
      "        \n",
      "        self.start_urls = [(TRACKS_URL % user) for user in user_names]\n",
      "\n",
      "    def parse(self, response):\n",
      "        tracks = json.loads(response.body)\n",
      "        if tracks:\n",
      "            for track_dict in tracks:\n",
      "                track_dict =  defaultdict(int, track_dict) # some track miss fields\n",
      "            track = Track()\n",
      "            track['sc_user_name'] = track_dict['user']['username']\n",
      "            track['artist_id'] = users_dict[track['sc_user_name']] #we look up the internal artist id\n",
      "            track['sc_track_id'] = track_dict['id']\n",
      "            track['sc_num_plays'] = track_dict['playback_count']\n",
      "            track['sc_description'] = track_dict['description']\n",
      "            track['sc_genre'] = track_dict['genre']\n",
      "            track['sc_embeddable_by'] = track_dict['embeddable_by']\n",
      "            track['sc_lable_name'] = track_dict['label_name']\n",
      "            track['sc_last_modiefied'] = track_dict['last_modiefied']\n",
      "            yield track\n",
      "            \n",
      "    def get_sc_users_without_tracks(self):\n",
      "        from db.dbmodel import db_connect, create_tables, ArtistPage, ThirdParty, ArtistSample\n",
      "        from sqlalchemy.orm import sessionmaker\n",
      "        \n",
      "        engine = db_connect()\n",
      "        create_tables(engine)\n",
      "        Session = sessionmaker(bind=engine)\n",
      "        s = Session()\n",
      "\n",
      "        left_outer = s.query(ArtistPage).join(ThirdParty).outerjoin(\n",
      "                        ArtistSample, ArtistPage.artist_id == ArtistSample.artist_id\n",
      "                        ).filter(ArtistSample.sample_id == None, ThirdParty.name == 'SoundCloud')\n",
      "\n",
      "        users = {a.page_id: a.artist_id for a in left_outer}\n",
      "\n",
      "        s.close()\n",
      "        return users\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Writing ra/spiders/sc_tracks.py\n"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import requests\n",
      "a = requests.get('http://www.residentadvisor.net/event.aspx?631670')\n",
      "response = HtmlResponse(a.url, body=a.content, encoding='utf8')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 232
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "BASE_URL = 'http://www.residentadvisor.net'\n",
      "extract_digits = re.compile(r'(\\d+)')\n",
      "event = Event()\n",
      "event['ra_url'] = response.url    \n",
      "event['ra_event_id'] = extract_digits.search(event['ra_url']).group(1)\n",
      "event['item_type'] = 'event'\n",
      "event['name'] = response.xpath(\"//div[@id = 'sectionHead']/h1/text()\").extract()[0]\n",
      "event['date'] = None #TODAY.isoformat()\n",
      "event['artists'] = []\n",
      "\n",
      "club_link = response.xpath(\"//a[contains(@title, 'Club profile')]\")\n",
      "if club_link:\n",
      "    club = Club()\n",
      "    club['ra_url'] = BASE_URL + '/' + club_link.xpath(\"@href\").extract()[0]\n",
      "    club['name'] = club_link.xpath(\"text()\").extract()[0]\n",
      "    id_match = extract_digits.search(club['ra_url'])\n",
      "    #self.log(type(id_match))\n",
      "    club['ra_club_id'] = id_match.group(1)\n",
      "    club['adress'] = club_link.xpath(\"../text()\").extract()[0]\n",
      "\n",
      "    #geocode = geocoder.google(club['adress'])\n",
      "    #if geocode.status_description == 'OK':\n",
      "    club['latlon'] = [0, 0] #geocode.latlng\n",
      "    #event['ra_club_id'] = club['ra_club_id']\n",
      "    event['club'] = club\n",
      "\n",
      "lineup_selector = response.css(\".lineup\").xpath(\"a\")\n",
      "if lineup_selector:\n",
      "    num_artists = len(lineup_selector)\n",
      "    for link_sel in lineup_selector:\n",
      "        artist = Artist()\n",
      "        url_ext = link_sel.xpath(\"@href\").extract()[0]\n",
      "        if url_ext[:4] == \"/dj/\":\n",
      "            artist['ra_url'] = BASE_URL + url_ext\n",
      "            artist['name'] = link_sel.xpath(\"text()\").extract()[0]\n",
      "            artist['ra_artist_id'] = url_ext.split(\"/\")[2]\n",
      "\n",
      "            #step into RA artist page\n",
      "            #request = scrapy.Request(artist['ra_url'], callback=self.parse_artist_page)\n",
      "            #request.meta['event'] = event\n",
      "            #request.meta['artist'] = artist\n",
      "            #request.meta['num_artists'] = num_artists"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 85
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def date_from_events_url(url):\n",
      "    from urlparse import parse_qs, urlparse\n",
      "    from datetime import date\n",
      "    date_dict =parse_qs(urlparse(url).query, keep_blank_values=True)\n",
      "    try:\n",
      "        y = int(date_dict['yr'][0])\n",
      "        m = int(date_dict['mn'][0])\n",
      "        d = int(date_dict['dy'][0])\n",
      "    except:\n",
      "        raise\n",
      "    return date(y, m , d)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 152
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 234
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 210
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_sc_users_without_tracks():\n",
      "    from db.dbmodel import db_connect, create_tables, ArtistPage, ThirdParty, ArtistSample\n",
      "    from sqlalchemy.orm import sessionmaker\n",
      "    engine = db_connect()\n",
      "    create_tables(engine)\n",
      "    Session = sessionmaker(bind=engine)\n",
      "    s = Session()\n",
      "\n",
      "    left_outer = s.query(ArtistPage).join(ThirdParty).outerjoin(\n",
      "                    ArtistSample, ArtistPage.artist_id == ArtistSample.artist_id\n",
      "                    ).filter(ArtistSample.sample_id == None, ThirdParty.name == 'SoundCloud')\n",
      "\n",
      "    users = {a.page_id: a.artist_id for a in left_outer}\n",
      "\n",
      "    s.close()\n",
      "    return users\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def parse_tracks(self, response):\n",
      "\n",
      "    artist = response.meta['artist']\n",
      "    event = response.meta['event']\n",
      "    tracks = json.loads(response.body)\n",
      "    if tracks:\n",
      "        tracks = [defaultdict(int, t) for t in tracks] #some tracks miss fields\n",
      "        permalinks_plays = [(t['id'], t['playback_count']) for t in tracks]\n",
      "        permalinks_plays.sort(key=lambda x: x[1], reverse=True)\n",
      "\n",
      "        artist['sc_track_id'] = permalinks_plays[0][0]\n",
      "        artist\n",
      "        artist['sc_value'] = sum((p for l, p in permalinks_plays))\n",
      "\n",
      "        event['artists'] = event['artists'] + [artist]\n",
      "        if len(event['artists']) == response.meta['num_artists']: #very hacky take this out!\n",
      "            yield event"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scrapy.contrib.linkextractors import LinkExtractor\n",
      "from scrapy.utils import request\n",
      "from scrapy.http.response import text\n",
      "import scrapy\n",
      "import re"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scrapy.selector import Selector\n",
      "from scrapy.http import HtmlResponse, Response\n",
      "from requests import get\n",
      "import urllib"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#url = 'http://www.residentadvisor.net/event.aspx?638376'\n",
      "#url = \"http://www.residentadvisor.net/dj/patrickpoitz\"\n",
      "url = \"http://api.soundcloud.com/users/agnes/tracks.json?\"+client_id\n",
      "req = get(url)\n",
      "body = get(url).text\n",
      "\n",
      "m = HtmlResponse(url=url, body=body, encoding='utf8')\n",
      "\n",
      "import json\n",
      "res = json.loads(m.body)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!rm ../../cm_naive/events/2014-09-27.json"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!scrapy crawl event_spider"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/alec/anaconda/lib/python2.7/site-packages/twisted/internet/_sslverify.py:184: UserWarning: You do not have the service_identity module installed. Please install it from <https://pypi.python.org/pypi/service_identity>. Without the service_identity module and a recent enough pyOpenSSL tosupport it, Twisted can perform only rudimentary TLS client hostnameverification.  Many valid certificate/hostname mappings may be rejected.\r\n",
        "  verifyHostname, VerificationError = _selectVerifyImplementation()\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2014-10-27 22:13:02+0100 [scrapy] INFO: Scrapy 0.24.4 started (bot: ra)\r\n",
        "2014-10-27 22:13:02+0100 [scrapy] INFO: Optional features available: ssl, http11, boto\r\n",
        "2014-10-27 22:13:02+0100 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'ra.spiders', 'SPIDER_MODULES': ['ra.spiders'], 'BOT_NAME': 'ra'}\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2014-10-27 22:13:02+0100 [scrapy] INFO: Enabled extensions: LogStats, TelnetConsole, CloseSpider, WebService, CoreStats, SpiderState\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2014-10-27 22:13:03+0100 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2014-10-27 22:13:03+0100 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware\r\n",
        "sssssssssss\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2014-10-27 22:13:03+0100 [scrapy] INFO: Enabled item pipelines: VenuePipeline, EventPipeline, ArtistPipeline\r\n",
        "2014-10-27 22:13:03+0100 [scrapy] INFO: Enabled item pipelines: VenuePipeline, EventPipeline, ArtistPipeline\r\n",
        "2014-10-27 22:13:03+0100 [event_spider] INFO: Spider opened\r\n",
        "2014-10-27 22:13:03+0100 [event_spider] INFO: Spider opened\r\n",
        "2014-10-27 22:13:03+0100 [event_spider] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\r\n",
        "2014-10-27 22:13:03+0100 [event_spider] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\r\n",
        "2014-10-27 22:13:03+0100 [scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023\r\n",
        "2014-10-27 22:13:03+0100 [scrapy] DEBUG: Web service listening on 127.0.0.1:6080\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2014-10-27 22:13:04+0100 [event_spider] DEBUG: Crawled (200) <GET http://www.residentadvisor.net/events.aspx?ai=34&yr=2014&mn=10&dy=27&v=day> (referer: None)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2014-10-27 22:13:04+0100 [event_spider] DEBUG: Crawled (200) <GET http://www.residentadvisor.net/event.aspx?639096> (referer: http://www.residentadvisor.net/events.aspx?ai=34&yr=2014&mn=10&dy=27&v=day)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2014-10-27 22:13:05+0100 [event_spider] DEBUG: Crawled (200) <GET http://www.residentadvisor.net/event.aspx?648723> (referer: http://www.residentadvisor.net/events.aspx?ai=34&yr=2014&mn=10&dy=27&v=day)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2014-10-27 22:13:05+0100 [event_spider] ERROR: Error processing {'artists': [],\r\n",
        "\t 'club': {'adress': u' Revaler Strasse 99; 10245 Berlin-Friedrichshain; Berlin;',\r\n",
        "\t 'lat': 52.50763269999999,\r\n",
        "\t 'lon': 13.4543612,\r\n",
        "\t 'name': u'Crack Bellmer',\r\n",
        "\t 'ra_club_id': u'57853',\r\n",
        "\t 'ra_url': u'http://www.residentadvisor.net/club.aspx?id=57853'},\r\n",
        "\t 'end_datetime': datetime.datetime(2014, 10, 28, 6, 0),\r\n",
        "\t 'item_type': 'event',\r\n",
        "\t 'name': u'Montag auf Cr\\xe4ck',\r\n",
        "\t 'ra_event_id': '648723',\r\n",
        "\t 'ra_url': 'http://www.residentadvisor.net/event.aspx?648723',\r\n",
        "\t 'start_datetime': datetime.datetime(2014, 10, 27, 20, 0)}\r\n",
        "\tTraceback (most recent call last):\r\n",
        "\t  File \"/home/alec/anaconda/lib/python2.7/site-packages/scrapy/middleware.py\", line 62, in _process_chain\r\n",
        "\t    return process_chain(self.methods[methodname], obj, *args)\r\n",
        "\t  File \"/home/alec/anaconda/lib/python2.7/site-packages/scrapy/utils/defer.py\", line 65, in process_chain\r\n",
        "\t    d.callback(input)\r\n",
        "\t  File \"/home/alec/anaconda/lib/python2.7/site-packages/twisted/internet/defer.py\", line 382, in callback\r\n",
        "\t    self._startRunCallbacks(result)\r\n",
        "\t  File \"/home/alec/anaconda/lib/python2.7/site-packages/twisted/internet/defer.py\", line 490, in _startRunCallbacks\r\n",
        "\t    self._runCallbacks()\r\n",
        "\t--- <exception caught here> ---\r\n",
        "\t  File \"/home/alec/anaconda/lib/python2.7/site-packages/twisted/internet/defer.py\", line 577, in _runCallbacks\r\n",
        "\t    current.result = callback(current.result, *args, **kw)\r\n",
        "\t  File \"/home/alec/workspace/cm/ra_scrape/ra/ra/pipelines.py\", line 70, in process_item\r\n",
        "\t    raise DropItem('Venue %s misses an obligatory field: %s' % club['ra_url'], key)\r\n",
        "\texceptions.TypeError: not enough arguments for format string\r\n",
        "\t\r\n",
        "2014-10-27 22:13:05+0100 [event_spider] ERROR: Error processing {'artists': [],\r\n",
        "\t 'club': {'adress': u' Revaler Strasse 99; 10245 Berlin-Friedrichshain; Berlin;',\r\n",
        "\t 'lat': 52.50763269999999,\r\n",
        "\t 'lon': 13.4543612,\r\n",
        "\t 'name': u'Crack Bellmer',\r\n",
        "\t 'ra_club_id': u'57853',\r\n",
        "\t 'ra_url': u'http://www.residentadvisor.net/club.aspx?id=57853'},\r\n",
        "\t 'end_datetime': datetime.datetime(2014, 10, 28, 6, 0),\r\n",
        "\t 'item_type': 'event',\r\n",
        "\t 'name': u'Montag auf Cr\\xe4ck',\r\n",
        "\t 'ra_event_id': '648723',\r\n",
        "\t 'ra_url': 'http://www.residentadvisor.net/event.aspx?648723',\r\n",
        "\t 'start_datetime': datetime.datetime(2014, 10, 27, 20, 0)}\r\n",
        "\tTraceback (most recent call last):\r\n",
        "\t  File \"/home/alec/anaconda/lib/python2.7/site-packages/scrapy/middleware.py\", line 62, in _process_chain\r\n",
        "\t    return process_chain(self.methods[methodname], obj, *args)\r\n",
        "\t  File \"/home/alec/anaconda/lib/python2.7/site-packages/scrapy/utils/defer.py\", line 65, in process_chain\r\n",
        "\t    d.callback(input)\r\n",
        "\t  File \"/home/alec/anaconda/lib/python2.7/site-packages/twisted/internet/defer.py\", line 382, in callback\r\n",
        "\t    self._startRunCallbacks(result)\r\n",
        "\t  File \"/home/alec/anaconda/lib/python2.7/site-packages/twisted/internet/defer.py\", line 490, in _startRunCallbacks\r\n",
        "\t    self._runCallbacks()\r\n",
        "\t--- <exception caught here> ---\r\n",
        "\t  File \"/home/alec/anaconda/lib/python2.7/site-packages/twisted/internet/defer.py\", line 577, in _runCallbacks\r\n",
        "\t    current.result = callback(current.result, *args, **kw)\r\n",
        "\t  File \"/home/alec/workspace/cm/ra_scrape/ra/ra/pipelines.py\", line 70, in process_item\r\n",
        "\t    raise DropItem('Venue %s misses an obligatory field: %s' % club['ra_url'], key)\r\n",
        "\texceptions.TypeError: not enough arguments for format string\r\n",
        "\t\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2014-10-27 22:13:05+0100 [event_spider] DEBUG: Crawled (200) <GET http://www.residentadvisor.net/event.aspx?639814> (referer: http://www.residentadvisor.net/events.aspx?ai=34&yr=2014&mn=10&dy=27&v=day)\r\n",
        "2014-10-27 22:13:05+0100 [event_spider] ERROR: Error processing {'artists': [],\r\n",
        "\t 'end_datetime': datetime.datetime(2014, 10, 28, 5, 0),\r\n",
        "\t 'item_type': 'event',\r\n",
        "\t 'name': u\"Fuckin' Monday\",\r\n",
        "\t 'ra_event_id': '639814',\r\n",
        "\t 'ra_url': 'http://www.residentadvisor.net/event.aspx?639814',\r\n",
        "\t 'start_datetime': datetime.datetime(2014, 10, 27, 22, 0)}\r\n",
        "\tTraceback (most recent call last):\r\n",
        "\t  File \"/home/alec/anaconda/lib/python2.7/site-packages/scrapy/middleware.py\", line 62, in _process_chain\r\n",
        "\t    return process_chain(self.methods[methodname], obj, *args)\r\n",
        "\t  File \"/home/alec/anaconda/lib/python2.7/site-packages/scrapy/utils/defer.py\", line 65, in process_chain\r\n",
        "\t    d.callback(input)\r\n",
        "\t  File \"/home/alec/anaconda/lib/python2.7/site-packages/twisted/internet/defer.py\", line 382, in callback\r\n",
        "\t    self._startRunCallbacks(result)\r\n",
        "\t  File \"/home/alec/anaconda/lib/python2.7/site-packages/twisted/internet/defer.py\", line 490, in _startRunCallbacks\r\n",
        "\t    self._runCallbacks()\r\n",
        "\t--- <exception caught here> ---\r\n",
        "\t  File \"/home/alec/anaconda/lib/python2.7/site-packages/twisted/internet/defer.py\", line 577, in _runCallbacks\r\n",
        "\t    current.result = callback(current.result, *args, **kw)\r\n",
        "\t  File \"/home/alec/workspace/cm/ra_scrape/ra/ra/pipelines.py\", line 45, in process_item\r\n",
        "\t    club = item['club']\r\n",
        "\t  File \"/home/alec/anaconda/lib/python2.7/site-packages/scrapy/item.py\", line 50, in __getitem__\r\n",
        "\t    return self._values[key]\r\n",
        "\texceptions.KeyError: 'club'\r\n",
        "\t\r\n",
        "2014-10-27 22:13:05+0100 [event_spider] ERROR: Error processing {'artists': [],\r\n",
        "\t 'end_datetime': datetime.datetime(2014, 10, 28, 5, 0),\r\n",
        "\t 'item_type': 'event',\r\n",
        "\t 'name': u\"Fuckin' Monday\",\r\n",
        "\t 'ra_event_id': '639814',\r\n",
        "\t 'ra_url': 'http://www.residentadvisor.net/event.aspx?639814',\r\n",
        "\t 'start_datetime': datetime.datetime(2014, 10, 27, 22, 0)}\r\n",
        "\tTraceback (most recent call last):\r\n",
        "\t  File \"/home/alec/anaconda/lib/python2.7/site-packages/scrapy/middleware.py\", line 62, in _process_chain\r\n",
        "\t    return process_chain(self.methods[methodname], obj, *args)\r\n",
        "\t  File \"/home/alec/anaconda/lib/python2.7/site-packages/scrapy/utils/defer.py\", line 65, in process_chain\r\n",
        "\t    d.callback(input)\r\n",
        "\t  File \"/home/alec/anaconda/lib/python2.7/site-packages/twisted/internet/defer.py\", line 382, in callback\r\n",
        "\t    self._startRunCallbacks(result)\r\n",
        "\t  File \"/home/alec/anaconda/lib/python2.7/site-packages/twisted/internet/defer.py\", line 490, in _startRunCallbacks\r\n",
        "\t    self._runCallbacks()\r\n",
        "\t--- <exception caught here> ---\r\n",
        "\t  File \"/home/alec/anaconda/lib/python2.7/site-packages/twisted/internet/defer.py\", line 577, in _runCallbacks\r\n",
        "\t    current.result = callback(current.result, *args, **kw)\r\n",
        "\t  File \"/home/alec/workspace/cm/ra_scrape/ra/ra/pipelines.py\", line 45, in process_item\r\n",
        "\t    club = item['club']\r\n",
        "\t  File \"/home/alec/anaconda/lib/python2.7/site-packages/scrapy/item.py\", line 50, in __getitem__\r\n",
        "\t    return self._values[key]\r\n",
        "\texceptions.KeyError: 'club'\r\n",
        "\t\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2014-10-27 22:13:06+0100 [event_spider] DEBUG: Crawled (200) <GET http://www.residentadvisor.net/event.aspx?643151> (referer: http://www.residentadvisor.net/events.aspx?ai=34&yr=2014&mn=10&dy=27&v=day)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2014-10-27 22:13:06+0100 [event_spider] DEBUG: Crawled (200) <GET http://www.residentadvisor.net/event.aspx?641386> (referer: http://www.residentadvisor.net/events.aspx?ai=34&yr=2014&mn=10&dy=27&v=day)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2014-10-27 22:13:07+0100 [event_spider] ERROR: Error processing {'artists': [],\r\n",
        "\t 'club': {'adress': u' Rigaer Strasse 31; Friedrichshain; 10247 Berlin;',\r\n",
        "\t 'lat': 52.51638999999999,\r\n",
        "\t 'lon': 13.46406,\r\n",
        "\t 'name': u'Minimal Bar',\r\n",
        "\t 'ra_club_id': u'23370',\r\n",
        "\t 'ra_url': u'http://www.residentadvisor.net/club.aspx?id=23370'},\r\n",
        "\t 'end_datetime': datetime.datetime(2014, 10, 28, 5, 0),\r\n",
        "\t 'item_type': 'event',\r\n",
        "\t 'name': u'Manic.Monday mit Gabriele Mancino',\r\n",
        "\t 'ra_event_id': '641386',\r\n",
        "\t 'ra_url': 'http://www.residentadvisor.net/event.aspx?641386',\r\n",
        "\t 'start_datetime': datetime.datetime(2014, 10, 27, 19, 0)}\r\n",
        "\tTraceback (most recent call last):\r\n",
        "\t  File \"/home/alec/anaconda/lib/python2.7/site-packages/scrapy/middleware.py\", line 62, in _process_chain\r\n",
        "\t    return process_chain(self.methods[methodname], obj, *args)\r\n",
        "\t  File \"/home/alec/anaconda/lib/python2.7/site-packages/scrapy/utils/defer.py\", line 65, in process_chain\r\n",
        "\t    d.callback(input)\r\n",
        "\t  File \"/home/alec/anaconda/lib/python2.7/site-packages/twisted/internet/defer.py\", line 382, in callback\r\n",
        "\t    self._startRunCallbacks(result)\r\n",
        "\t  File \"/home/alec/anaconda/lib/python2.7/site-packages/twisted/internet/defer.py\", line 490, in _startRunCallbacks\r\n",
        "\t    self._runCallbacks()\r\n",
        "\t--- <exception caught here> ---\r\n",
        "\t  File \"/home/alec/anaconda/lib/python2.7/site-packages/twisted/internet/defer.py\", line 577, in _runCallbacks\r\n",
        "\t    current.result = callback(current.result, *args, **kw)\r\n",
        "\t  File \"/home/alec/workspace/cm/ra_scrape/ra/ra/pipelines.py\", line 70, in process_item\r\n",
        "\t    raise DropItem('Venue %s misses an obligatory field: %s' % club['ra_url'], key)\r\n",
        "\texceptions.TypeError: not enough arguments for format string\r\n",
        "\t\r\n",
        "2014-10-27 22:13:07+0100 [event_spider] ERROR: Error processing {'artists': [],\r\n",
        "\t 'club': {'adress': u' Rigaer Strasse 31; Friedrichshain; 10247 Berlin;',\r\n",
        "\t 'lat': 52.51638999999999,\r\n",
        "\t 'lon': 13.46406,\r\n",
        "\t 'name': u'Minimal Bar',\r\n",
        "\t 'ra_club_id': u'23370',\r\n",
        "\t 'ra_url': u'http://www.residentadvisor.net/club.aspx?id=23370'},\r\n",
        "\t 'end_datetime': datetime.datetime(2014, 10, 28, 5, 0),\r\n",
        "\t 'item_type': 'event',\r\n",
        "\t 'name': u'Manic.Monday mit Gabriele Mancino',\r\n",
        "\t 'ra_event_id': '641386',\r\n",
        "\t 'ra_url': 'http://www.residentadvisor.net/event.aspx?641386',\r\n",
        "\t 'start_datetime': datetime.datetime(2014, 10, 27, 19, 0)}\r\n",
        "\tTraceback (most recent call last):\r\n",
        "\t  File \"/home/alec/anaconda/lib/python2.7/site-packages/scrapy/middleware.py\", line 62, in _process_chain\r\n",
        "\t    return process_chain(self.methods[methodname], obj, *args)\r\n",
        "\t  File \"/home/alec/anaconda/lib/python2.7/site-packages/scrapy/utils/defer.py\", line 65, in process_chain\r\n",
        "\t    d.callback(input)\r\n",
        "\t  File \"/home/alec/anaconda/lib/python2.7/site-packages/twisted/internet/defer.py\", line 382, in callback\r\n",
        "\t    self._startRunCallbacks(result)\r\n",
        "\t  File \"/home/alec/anaconda/lib/python2.7/site-packages/twisted/internet/defer.py\", line 490, in _startRunCallbacks\r\n",
        "\t    self._runCallbacks()\r\n",
        "\t--- <exception caught here> ---\r\n",
        "\t  File \"/home/alec/anaconda/lib/python2.7/site-packages/twisted/internet/defer.py\", line 577, in _runCallbacks\r\n",
        "\t    current.result = callback(current.result, *args, **kw)\r\n",
        "\t  File \"/home/alec/workspace/cm/ra_scrape/ra/ra/pipelines.py\", line 70, in process_item\r\n",
        "\t    raise DropItem('Venue %s misses an obligatory field: %s' % club['ra_url'], key)\r\n",
        "\texceptions.TypeError: not enough arguments for format string\r\n",
        "\t\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2014-10-27 22:13:09+0100 [event_spider] DEBUG: Crawled (200) <GET http://www.residentadvisor.net/dj/ollidertwist> (referer: http://www.residentadvisor.net/event.aspx?643151)\r\n",
        "2014-10-27 22:13:09+0100 [event_spider] ERROR: Error processing {'artists': [{'name': u'Ollider Twist',\r\n",
        "\t 'ra_artist_id': u'ollidertwist',\r\n",
        "\t 'ra_url': u'http://www.residentadvisor.net/dj/ollidertwist',\r\n",
        "\t 'sc_url': u'http://www.soundcloud.com/https://ollider-twist',\r\n",
        "\t 'sc_user': u'ollider-twist'}],\r\n",
        "\t 'club': {'adress': u' Schillerpromenade 11, 12049 Berlin',\r\n",
        "\t 'lat': 52.475866,\r\n",
        "\t 'lon': 13.4220073,\r\n",
        "\t 'name': u'Promenaden Eck',\r\n",
        "\t 'ra_club_id': u'88900',\r\n",
        "\t 'ra_url': u'http://www.residentadvisor.net/club.aspx?id=88900'},\r\n",
        "\t 'end_datetime': datetime.datetime(2014, 10, 28, 4, 0),\r\n",
        "\t 'item_type': 'event',\r\n",
        "\t 'name': u'Let\\xb4s Stay Awake with Ollider Twist',\r\n",
        "\t 'ra_event_id': '643151',\r\n",
        "\t 'ra_url': 'http://www.residentadvisor.net/event.aspx?643151',\r\n",
        "\t 'start_datetime': datetime.datetime(2014, 10, 27, 19, 0)}\r\n",
        "\tTraceback (most recent call last):\r\n",
        "\t  File \"/home/alec/anaconda/lib/python2.7/site-packages/scrapy/middleware.py\", line 62, in _process_chain\r\n",
        "\t    return process_chain(self.methods[methodname], obj, *args)\r\n",
        "\t  File \"/home/alec/anaconda/lib/python2.7/site-packages/scrapy/utils/defer.py\", line 65, in process_chain\r\n",
        "\t    d.callback(input)\r\n",
        "\t  File \"/home/alec/anaconda/lib/python2.7/site-packages/twisted/internet/defer.py\", line 382, in callback\r\n",
        "\t    self._startRunCallbacks(result)\r\n",
        "\t  File \"/home/alec/anaconda/lib/python2.7/site-packages/twisted/internet/defer.py\", line 490, in _startRunCallbacks\r\n",
        "\t    self._runCallbacks()\r\n",
        "\t--- <exception caught here> ---\r\n",
        "\t  File \"/home/alec/anaconda/lib/python2.7/site-packages/twisted/internet/defer.py\", line 577, in _runCallbacks\r\n",
        "\t    current.result = callback(current.result, *args, **kw)\r\n",
        "\t  File \"/home/alec/workspace/cm/ra_scrape/ra/ra/pipelines.py\", line 70, in process_item\r\n",
        "\t    raise DropItem('Venue %s misses an obligatory field: %s' % club['ra_url'], key)\r\n",
        "\texceptions.TypeError: not enough arguments for format string\r\n",
        "\t\r\n",
        "2014-10-27 22:13:09+0100 [event_spider] ERROR: Error processing {'artists': [{'name': u'Ollider Twist',\r\n",
        "\t 'ra_artist_id': u'ollidertwist',\r\n",
        "\t 'ra_url': u'http://www.residentadvisor.net/dj/ollidertwist',\r\n",
        "\t 'sc_url': u'http://www.soundcloud.com/https://ollider-twist',\r\n",
        "\t 'sc_user': u'ollider-twist'}],\r\n",
        "\t 'club': {'adress': u' Schillerpromenade 11, 12049 Berlin',\r\n",
        "\t 'lat': 52.475866,\r\n",
        "\t 'lon': 13.4220073,\r\n",
        "\t 'name': u'Promenaden Eck',\r\n",
        "\t 'ra_club_id': u'88900',\r\n",
        "\t 'ra_url': u'http://www.residentadvisor.net/club.aspx?id=88900'},\r\n",
        "\t 'end_datetime': datetime.datetime(2014, 10, 28, 4, 0),\r\n",
        "\t 'item_type': 'event',\r\n",
        "\t 'name': u'Let\\xb4s Stay Awake with Ollider Twist',\r\n",
        "\t 'ra_event_id': '643151',\r\n",
        "\t 'ra_url': 'http://www.residentadvisor.net/event.aspx?643151',\r\n",
        "\t 'start_datetime': datetime.datetime(2014, 10, 27, 19, 0)}\r\n",
        "\tTraceback (most recent call last):\r\n",
        "\t  File \"/home/alec/anaconda/lib/python2.7/site-packages/scrapy/middleware.py\", line 62, in _process_chain\r\n",
        "\t    return process_chain(self.methods[methodname], obj, *args)\r\n",
        "\t  File \"/home/alec/anaconda/lib/python2.7/site-packages/scrapy/utils/defer.py\", line 65, in process_chain\r\n",
        "\t    d.callback(input)\r\n",
        "\t  File \"/home/alec/anaconda/lib/python2.7/site-packages/twisted/internet/defer.py\", line 382, in callback\r\n",
        "\t    self._startRunCallbacks(result)\r\n",
        "\t  File \"/home/alec/anaconda/lib/python2.7/site-packages/twisted/internet/defer.py\", line 490, in _startRunCallbacks\r\n",
        "\t    self._runCallbacks()\r\n",
        "\t--- <exception caught here> ---\r\n",
        "\t  File \"/home/alec/anaconda/lib/python2.7/site-packages/twisted/internet/defer.py\", line 577, in _runCallbacks\r\n",
        "\t    current.result = callback(current.result, *args, **kw)\r\n",
        "\t  File \"/home/alec/workspace/cm/ra_scrape/ra/ra/pipelines.py\", line 70, in process_item\r\n",
        "\t    raise DropItem('Venue %s misses an obligatory field: %s' % club['ra_url'], key)\r\n",
        "\texceptions.TypeError: not enough arguments for format string\r\n",
        "\t\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2014-10-27 22:13:12+0100 [event_spider] DEBUG: Crawled (200) <GET http://www.residentadvisor.net/dj/younotus> (referer: http://www.residentadvisor.net/event.aspx?639096)\r\n",
        "2014-10-27 22:13:12+0100 [event_spider] ERROR: Error processing {'artists': [{'name': u'Younotus',\r\n",
        "\t 'ra_artist_id': u'younotus',\r\n",
        "\t 'ra_url': u'http://www.residentadvisor.net/dj/younotus'}],\r\n",
        "\t 'club': {'adress': u' K\\xf6penickerstrasse 70; Mitte; 10179 Berlin;',\r\n",
        "\t 'lat': 52.5108799,\r\n",
        "\t 'lon': 13.4201002,\r\n",
        "\t 'name': u'Tresor',\r\n",
        "\t 'ra_club_id': u'5494',\r\n",
        "\t 'ra_url': u'http://www.residentadvisor.net/club.aspx?id=5494'},\r\n",
        "\t 'end_datetime': datetime.datetime(2014, 10, 28, 9, 0),\r\n",
        "\t 'item_type': 'event',\r\n",
        "\t 'name': u'House OF Waxx',\r\n",
        "\t 'ra_event_id': '639096',\r\n",
        "\t 'ra_url': 'http://www.residentadvisor.net/event.aspx?639096',\r\n",
        "\t 'start_datetime': datetime.datetime(2014, 10, 27, 23, 59)}\r\n",
        "\tTraceback (most recent call last):\r\n",
        "\t  File \"/home/alec/anaconda/lib/python2.7/site-packages/scrapy/middleware.py\", line 62, in _process_chain\r\n",
        "\t    return process_chain(self.methods[methodname], obj, *args)\r\n",
        "\t  File \"/home/alec/anaconda/lib/python2.7/site-packages/scrapy/utils/defer.py\", line 65, in process_chain\r\n",
        "\t    d.callback(input)\r\n",
        "\t  File \"/home/alec/anaconda/lib/python2.7/site-packages/twisted/internet/defer.py\", line 382, in callback\r\n",
        "\t    self._startRunCallbacks(result)\r\n",
        "\t  File \"/home/alec/anaconda/lib/python2.7/site-packages/twisted/internet/defer.py\", line 490, in _startRunCallbacks\r\n",
        "\t    self._runCallbacks()\r\n",
        "\t--- <exception caught here> ---\r\n",
        "\t  File \"/home/alec/anaconda/lib/python2.7/site-packages/twisted/internet/defer.py\", line 577, in _runCallbacks\r\n",
        "\t    current.result = callback(current.result, *args, **kw)\r\n",
        "\t  File \"/home/alec/workspace/cm/ra_scrape/ra/ra/pipelines.py\", line 70, in process_item\r\n",
        "\t    raise DropItem('Venue %s misses an obligatory field: %s' % club['ra_url'], key)\r\n",
        "\texceptions.TypeError: not enough arguments for format string\r\n",
        "\t\r\n",
        "2014-10-27 22:13:12+0100 [event_spider] ERROR: Error processing {'artists': [{'name': u'Younotus',\r\n",
        "\t 'ra_artist_id': u'younotus',\r\n",
        "\t 'ra_url': u'http://www.residentadvisor.net/dj/younotus'}],\r\n",
        "\t 'club': {'adress': u' K\\xf6penickerstrasse 70; Mitte; 10179 Berlin;',\r\n",
        "\t 'lat': 52.5108799,\r\n",
        "\t 'lon': 13.4201002,\r\n",
        "\t 'name': u'Tresor',\r\n",
        "\t 'ra_club_id': u'5494',\r\n",
        "\t 'ra_url': u'http://www.residentadvisor.net/club.aspx?id=5494'},\r\n",
        "\t 'end_datetime': datetime.datetime(2014, 10, 28, 9, 0),\r\n",
        "\t 'item_type': 'event',\r\n",
        "\t 'name': u'House OF Waxx',\r\n",
        "\t 'ra_event_id': '639096',\r\n",
        "\t 'ra_url': 'http://www.residentadvisor.net/event.aspx?639096',\r\n",
        "\t 'start_datetime': datetime.datetime(2014, 10, 27, 23, 59)}\r\n",
        "\tTraceback (most recent call last):\r\n",
        "\t  File \"/home/alec/anaconda/lib/python2.7/site-packages/scrapy/middleware.py\", line 62, in _process_chain\r\n",
        "\t    return process_chain(self.methods[methodname], obj, *args)\r\n",
        "\t  File \"/home/alec/anaconda/lib/python2.7/site-packages/scrapy/utils/defer.py\", line 65, in process_chain\r\n",
        "\t    d.callback(input)\r\n",
        "\t  File \"/home/alec/anaconda/lib/python2.7/site-packages/twisted/internet/defer.py\", line 382, in callback\r\n",
        "\t    self._startRunCallbacks(result)\r\n",
        "\t  File \"/home/alec/anaconda/lib/python2.7/site-packages/twisted/internet/defer.py\", line 490, in _startRunCallbacks\r\n",
        "\t    self._runCallbacks()\r\n",
        "\t--- <exception caught here> ---\r\n",
        "\t  File \"/home/alec/anaconda/lib/python2.7/site-packages/twisted/internet/defer.py\", line 577, in _runCallbacks\r\n",
        "\t    current.result = callback(current.result, *args, **kw)\r\n",
        "\t  File \"/home/alec/workspace/cm/ra_scrape/ra/ra/pipelines.py\", line 70, in process_item\r\n",
        "\t    raise DropItem('Venue %s misses an obligatory field: %s' % club['ra_url'], key)\r\n",
        "\texceptions.TypeError: not enough arguments for format string\r\n",
        "\t\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2014-10-27 22:13:12+0100 [event_spider] INFO: Closing spider (finished)\r\n",
        "2014-10-27 22:13:12+0100 [event_spider] INFO: Closing spider (finished)\r\n",
        "2014-10-27 22:13:12+0100 [event_spider] INFO: Dumping Scrapy stats:\r\n",
        "\t{'downloader/request_bytes': 2837,\r\n",
        "\t 'downloader/request_count': 8,\r\n",
        "\t 'downloader/request_method_count/GET': 8,\r\n",
        "\t 'downloader/response_bytes': 201260,\r\n",
        "\t 'downloader/response_count': 8,\r\n",
        "\t 'downloader/response_status_count/200': 8,\r\n",
        "\t 'finish_reason': 'finished',\r\n",
        "\t 'finish_time': datetime.datetime(2014, 10, 27, 21, 13, 12, 624931),\r\n",
        "\t 'log_count/DEBUG': 10,\r\n",
        "\t 'log_count/ERROR': 5,\r\n",
        "\t 'log_count/INFO': 7,\r\n",
        "\t 'request_depth_max': 2,\r\n",
        "\t 'response_received_count': 8,\r\n",
        "\t 'scheduler/dequeued': 8,\r\n",
        "\t 'scheduler/dequeued/memory': 8,\r\n",
        "\t 'scheduler/enqueued': 8,\r\n",
        "\t 'scheduler/enqueued/memory': 8,\r\n",
        "\t 'start_time': datetime.datetime(2014, 10, 27, 21, 13, 3, 878884)}\r\n",
        "2014-10-27 22:13:12+0100 [event_spider] INFO: Dumping Scrapy stats:\r\n",
        "\t{'downloader/request_bytes': 2837,\r\n",
        "\t 'downloader/request_count': 8,\r\n",
        "\t 'downloader/request_method_count/GET': 8,\r\n",
        "\t 'downloader/response_bytes': 201260,\r\n",
        "\t 'downloader/response_count': 8,\r\n",
        "\t 'downloader/response_status_count/200': 8,\r\n",
        "\t 'finish_reason': 'finished',\r\n",
        "\t 'finish_time': datetime.datetime(2014, 10, 27, 21, 13, 12, 624931),\r\n",
        "\t 'log_count/DEBUG': 10,\r\n",
        "\t 'log_count/ERROR': 5,\r\n",
        "\t 'log_count/INFO': 7,\r\n",
        "\t 'request_depth_max': 2,\r\n",
        "\t 'response_received_count': 8,\r\n",
        "\t 'scheduler/dequeued': 8,\r\n",
        "\t 'scheduler/dequeued/memory': 8,\r\n",
        "\t 'scheduler/enqueued': 8,\r\n",
        "\t 'scheduler/enqueued/memory': 8,\r\n",
        "\t 'start_time': datetime.datetime(2014, 10, 27, 21, 13, 3, 878884)}\r\n",
        "2014-10-27 22:13:12+0100 [event_spider] INFO: Spider closed (finished)\r\n",
        "2014-10-27 22:13:12+0100 [event_spider] INFO: Spider closed (finished)\r\n"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cat a.json"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[{\"name\": \"House of Waxx at Tresor\", \"url\": \"http://www.residentadvisor.net/event.aspx?629290\", \"club\": {\"url\": \"club.aspx?id=5494\", \"latlon\": [52.5108799, 13.4201002], \"ra_club_id\": \"5494\", \"adress\": \" K\\u00f6penickerstrasse 70; Mitte; 10179 Berlin;\", \"name\": \"Tresor\"}, \"artists\": [{\"ra_artist_id\": \"gunnarstiller\", \"sc_track_permalink\": \"http://soundcloud.com/gunnar-stiller/panoramabar_2011-10-23\", \"name\": \"Gunnar Stiller\", \"sc_user\": \"gunnar-stiller\", \"url\": \"http://www.residentadvisor.net/dj/gunnarstiller\", \"sc_value\": 112417, \"sc_link\": \"http://www.soundcloud.com/gunnar-stiller\"}, {\"ra_artist_id\": \"axelbartsch\", \"sc_track_permalink\": \"http://soundcloud.com/axelbartsch/katerholzig-daytime-dj-action\", \"name\": \"Axel Bartsch\", \"sc_user\": \"axelbartsch\", \"url\": \"http://www.residentadvisor.net/dj/axelbartsch\", \"sc_value\": 38713, \"sc_link\": \"http://www.soundcloud.com/axelbartsch\"}], \"date\": \"2014-09-29\", \"ra_club_id\": \"5494\", \"ra_event_id\": \"629290\"},\r\n",
        "{\"url\": \"http://www.residentadvisor.net/event.aspx?629227\", \"date\": \"2014-09-29\", \"artists\": [{\"ra_artist_id\": \"tiny\", \"sc_track_permalink\": \"http://soundcloud.com/tiney/done-by-the-dawgs\", \"name\": \"Tiny\", \"sc_user\": \"tiney\", \"url\": \"http://www.residentadvisor.net/dj/tiny\", \"sc_value\": 3077, \"sc_link\": \"http://www.soundcloud.com/tiney\"}], \"ra_event_id\": \"629227\", \"name\": \"Tiny Ruins at Gr\\u00fcner Salon Der Volksb\\u00fchne\"},\r\n",
        "{\"name\": \"Let's Stay Awake mit Ollider Twist at Promenaden Eck\", \"url\": \"http://www.residentadvisor.net/event.aspx?632989\", \"club\": {\"url\": \"club.aspx?id=88900\", \"latlon\": [52.475866, 13.4220073], \"ra_club_id\": \"88900\", \"adress\": \" Schillerpromenade 11, 12049 Berlin\", \"name\": \"Promenaden Eck\"}, \"artists\": [{\"ra_artist_id\": \"ollidertwist\", \"sc_track_permalink\": \"http://soundcloud.com/ollider-twist/ick-hau-van-jau\", \"name\": \"Ollider Twist\", \"sc_user\": \"ollider-twist\", \"url\": \"http://www.residentadvisor.net/dj/ollidertwist\", \"sc_value\": 1682, \"sc_link\": \"http://www.soundcloud.com/https://ollider-twist\"}], \"date\": \"2014-09-29\", \"ra_club_id\": \"88900\", \"ra_event_id\": \"632989\"},\r\n",
        "{\"name\": \"Electro Funk Roots at Cake Club\", \"url\": \"http://www.residentadvisor.net/event.aspx?628859\", \"club\": {\"url\": \"club.aspx?id=42409\", \"latlon\": [52.5016358, 13.41866], \"ra_club_id\": \"42409\", \"adress\": \" Oranienstra\\u00dfe 32 10999 Berlin\", \"name\": \"Cake Club\"}, \"artists\": [{\"ra_artist_id\": \"djdannyrussell\", \"sc_track_permalink\": \"http://soundcloud.com/dj-danny-russell/electro-funk-roots-mix\", \"name\": \"DJ Danny Russell\", \"sc_user\": \"dj-danny-russell\", \"url\": \"http://www.residentadvisor.net/dj/djdannyrussell\", \"sc_value\": 1622, \"sc_link\": \"http://www.soundcloud.com/dj-danny-russell\"}], \"date\": \"2014-09-29\", \"ra_club_id\": \"42409\", \"ra_event_id\": \"628859\"}]"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "id_extract=re.compile(r'(\\d+)')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "g = id_extract.search(\"http://www.residentadvisor.net/event.aspx?632254\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "g.group()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 40,
       "text": [
        "'632254'"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}